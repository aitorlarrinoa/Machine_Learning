{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8b9112",
   "metadata": {},
   "source": [
    "# ANÁLISIS DE SINIESTRALIDAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b3b778",
   "metadata": {},
   "source": [
    "### CUNEF MUCD (2021/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57937ff4",
   "metadata": {},
   "source": [
    "- Aitor Larriona Rementería\n",
    "- Diego Cendán Bedregal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84148e",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69660d5d",
   "metadata": {},
   "source": [
    "## LIBRERÍAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3f39a",
   "metadata": {},
   "source": [
    "Librerías básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b8f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from statistics import mode, multimode\n",
    "import time\n",
    "import sklearn\n",
    "import warnings\n",
    "import scikitplot as skplt\n",
    "import statsmodels.api as sapi\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9faaec",
   "metadata": {},
   "source": [
    "Funciones para métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268c9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve,precision_score, accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10095495",
   "metadata": {},
   "source": [
    "Librerías para modelos y para selección de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbbc17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a41f7",
   "metadata": {},
   "source": [
    "Importamos el pipeline y pickle (para guardar los modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0252929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda5d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa21b73",
   "metadata": {},
   "source": [
    "Importamos también las funciones necesarias en este notebook del archivo FUNCIONES.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0575f1ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de1aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run FUNCIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73deb7ca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916636e1",
   "metadata": {},
   "source": [
    "## Lectura de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f4adf",
   "metadata": {},
   "source": [
    "Cargamos los conjuntos de training y testing que hemos obtenido en el notebook *02*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c2a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_X_train= pq.read_table('/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big_practice_data/X_train_oversampled.parquet')\n",
    "X_train_oversampled = table_X_train.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e795b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_y_train= pq.read_table('/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big_practice_data/y_train_oversampled.parquet')\n",
    "y_train_oversampled = table_y_train.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a9e75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_X_test= pq.read_table('/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big_practice_data/x_test.parquet')\n",
    "x_test = table_X_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c77dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_y_test= pq.read_table('/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big_practice_data/ytest.parquet')\n",
    "ytest = table_y_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b01c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table('/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big_practice_data/pd_data.parquet')\n",
    "df_pd_data = table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261fbc5a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45462e",
   "metadata": {},
   "source": [
    "## MODELO BASE (aleatorio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be28135",
   "metadata": {},
   "source": [
    "En el modelo base trataremos de generar un vector aleatorio de 1s y 2s dando pesos a cada uno de estos dos valores. Los pesos los eligiremos en función de la distribución que tiene nuestra variable target en nuestro dataset. Después de generar este vector aleatorio compararemos el vector real y el predicho para obtener el accuracy del modelo aleatorio principalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "645e85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_base(variable_target):\n",
    "    predic_modelo_base = list()\n",
    "    for i in range(len(variable_target)):\n",
    "        predic_modelo_base.append(random.choices([2,1], [98.315807, 1.684193]))\n",
    "    return predic_modelo_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afbea7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_MB = modelo_base(df_pd_data[\"C_SEV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4128d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.01      0.02      0.01     56857\n",
      "           2       0.99      0.98      0.98   3845257\n",
      "\n",
      "    accuracy                           0.97   3902114\n",
      "   macro avg       0.50      0.50      0.50   3902114\n",
      "weighted avg       0.97      0.97      0.97   3902114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_pd_data[\"C_SEV\"], predictions_MB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3b13f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normalized confusion matrix')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_gbt_MB = confusion_matrix(df_pd_data[\"C_SEV\"], predictions_MB)\n",
    "cm_gbt_norm_MB = confusion_matrix(df_pd_data[\"C_SEV\"], predictions_MB, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_gbt_MB, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_gbt_norm_MB, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953064b",
   "metadata": {},
   "source": [
    "Podemos observar como el modelo base tiene un accuracy de 0.97 y las matrices de confusión son bastante malas ya que solamente se centran en predecir los no fallecimientos (debido al desbalanceo del dataset). Pero este modelo será nuestro modelo de referencia y, a partir de aquí, los modelos que vayamos obteniendo deberán ir mejorando este."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c093e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c21229",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490bba6",
   "metadata": {},
   "source": [
    "Lasso es una penalización dentro de las regresiones. Antes de explicar Lasso, debemos explicar qué es una penalización. \n",
    "\n",
    "**Def.** Una regularización es una penalización. Lo que se busca con la regularización es obligar, de alguna forma, a que el modelo elija las variables más importantes en función de un threshold. \n",
    "\n",
    "Esto será entendido de manera más clara con el caso particular de regularización *Lasso*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57de5d8",
   "metadata": {},
   "source": [
    "Supongamos que para un modelo dado, calculamos el error cuadrático medio o, también conocido por *MSE*. El error cuadrático medio se define de la siguiente forma:\n",
    "<p style=\"text-align: center;\">\n",
    "MSE = $\\sum_{i=1}^{M} (y_i - \\bar{y}_i)^2$, tal que $\\bar{y}_i$ y $y_i$ se refieren al valor predicho y al valor real respectivamente\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9b06f",
   "metadata": {},
   "source": [
    "Donde M es el número de muestras que tenemos. Luego, lo que se pretende hacer con la regularización Lasso es añadir un término de manera que penalice este error cuadrático medio. En otras palabras, el término de Lasso hará mas grande el MSE. Para escribir el desarrollo de manera adecuada, supongamos que tenemos una regresión lineal que se escribe de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5cb0c",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "$\\bar{y} = w_{0} + w_{1}*x_{1} + w_{2}*x_{2} + ... + w_{n}*x_{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178ea72",
   "metadata": {},
   "source": [
    "Luego, nuestra predicción $\\bar{y}$ no será mas que $w_{1}*x_{1} + w_{2}*x_{2} + ... + w_{n}*x_{n}$. Entonces, podemos escribir el error cuadrático medio como sigue:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd05354",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "MSE = $\\sum_{i=1}^{M} (y_i - w_{0} - \\sum_{j=1}^{n}w_{j}*x_{ij})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db79452",
   "metadata": {},
   "source": [
    "Ahora, añadimos la penalización Lasso al error cuadrático medio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c8376",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "MSE = $\\sum_{i=1}^{M} (y_i - w_{0} - \\sum_{j=1}^{n}w_{j}*x_{ij})^2 + \\lambda*\\sum_{j=0}^{n}w_{j}^2$ tal que $\\lambda \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192c762",
   "metadata": {},
   "source": [
    "Es decir, obligamos a los coeficientes que sean muy bajos para que el error cuadrático medio no aumente exageradamente. El valor $\\lambda$ indicará *cuánto quiero que importe esta penalización*. Esto nos dará como resultado que un número de variables serán más importantes que otras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874a4c7",
   "metadata": {},
   "source": [
    "**Importante.** Para hacer uso de Lasso, es necesario escalar las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9b264",
   "metadata": {},
   "source": [
    "Una vez vista la teoría, adentrémonos en la práctica. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86855a78",
   "metadata": {},
   "source": [
    "**Varibales a utilizar**\n",
    "- *X_train_oversampled*: Dataset de training con la técnica de oversampling sin la variable respuesta \n",
    "- *y_train_oversampled*: Dataset de training de la variable target con la técnica de oversampling\n",
    "- *x_test*: Dataset de testing sin la variable target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c094c36",
   "metadata": {},
   "source": [
    "**Librerias a utilizar**\n",
    "- SelectFromModel de sklearn.feature_selection \n",
    "- LogisticRegression, LinearRegression de sklearn.linear_model \n",
    "- Sklearn.metrics \n",
    "- Matplotlib.pyplot\n",
    "- Pandas\n",
    "- Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd2143",
   "metadata": {},
   "source": [
    "Primeramente, vamos a comprobar como evoluciona el número de variables y el roc_auc_score en función del threshold para un modelo de regresión logística (nos servirá para más adelante) y así poder elegir el modelo Lasso adeacuado para este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86057967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aitor/opt/anaconda3/envs/ML_big_practice/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "num_var=list()\n",
    "ROC_score=list()\n",
    "for i in np.arange(0.05, 0.15, 0.005):\n",
    "    sel_lasso = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear', max_iter=100), threshold = i)\n",
    "    sel_lasso.fit(X_train_oversampled, y_train_oversampled)\n",
    "    selected_feat_lasso = X_train_oversampled.columns[sel_lasso.get_support()]\n",
    "    model = LogisticRegression(random_state=0)\n",
    "    model.fit(X_train_oversampled[selected_feat_lasso], y_train_oversampled)\n",
    "    sel_lasso.get_support()\n",
    "    predictions_proba=model.predict_proba(x_test[selected_feat_lasso])\n",
    "    num_var.append(len(selected_feat_lasso))\n",
    "    ROC_score.append(roc_auc_score(ytest, predictions_proba[:,1]))\n",
    "    # hacemos print de i para saber en cada momento por qué punto va el bucle\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3846d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"threshold\" :np.arange(0.05, 0.15, 0.005), 'Num_of_var':num_var, 'roc_score':ROC_score }\n",
    "threshold_df = pd.DataFrame(data, columns=[\"threshold\", \"Num_of_var\", \"roc_score\"])\n",
    "threshold_df.index=threshold_df[\"threshold\"]\n",
    "threshold_df.drop(\"threshold\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8636e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = threshold_df[\"Num_of_var\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a657669",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = threshold_df[\"roc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0e166",
   "metadata": {},
   "source": [
    "Viendo las gráficas, vemos que la segunda nos puede aportar quizás más información que la primera. Luego, basándonos en la segunda gráfica, podemos considerar como un buen threshold 0.1 ya que no perdemos mucho roc_auc_score y, nos quedamos con alrededor de 29 variables (gráfica de arriba).\n",
    "\n",
    "Luego, calculemos Lasso con dicho threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_Lasso = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca741c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_lasso = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'), threshold = 0.1) \n",
    "sel_lasso.fit(X_train_oversampled, y_train_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_lasso.get_support()\n",
    "selected_feat_lasso = X_train_oversampled.columns[sel_lasso.get_support()]\n",
    "selected_feat_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169563e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total features: {}'.format((X_train_oversampled.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat_lasso)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_Lasso = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeficientes_lasso = pd.DataFrame(\n",
    "                        {'predictor': X_train_oversampled.columns,\n",
    "                         'coef': sel_lasso.estimator_.coef_.flatten()}\n",
    "                  )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 3.84))\n",
    "ax.stem(df_coeficientes_lasso.predictor, df_coeficientes_lasso.coef, markerfmt=' ')\n",
    "plt.xticks(rotation=90, ha='right', size=10)\n",
    "ax.set_xlabel('variable')\n",
    "ax.set_ylabel('coeficientes')\n",
    "ax.set_title('Coeficientes del modelo lasso');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e05730",
   "metadata": {},
   "source": [
    "En este gráfico podemos ver cuáles son las variables más \"importantes\" con respecto a Lasso. En el gráfico aparecen todas las variables de nuestro dataset y, las que menos importancia tienen son num_Random, num_C_YEAR, NA_sin_C_WDAY, NA_cos_C_MNTH. Luego, estas son las variables que eliminamos de nuestra importancia de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc2c99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a11d8f",
   "metadata": {},
   "source": [
    "# SELECCIÓN DE VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a38334",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e3ca2",
   "metadata": {},
   "source": [
    "**Def**. El PCA o también conocido como análisis de componentes principales, es una técnica de reducción de dimensiones. Esta reducción de dimensiones se intenta que la varianza explicada por ellas sea lo mayor posible.\n",
    "\n",
    "A continuación mostramos una descripción detallada del algoritmo PCA\n",
    "\n",
    "El algoritmo tiene distintas fases, que explicamos a continuación:\n",
    "- *Estandarización de los datos*. Estandarización implica tomar cada valor en una columna y restarle la media de dicha columna y luego dividir por la desviación típica de la columna.\n",
    "- *Cálculo de la matriz de covarianzas*. La matriz de covarianzas es una matriz simétrica que en la diagonal principal tiene la varianza de las variables y en el resto de elementos (i,j) de la matriz la covarianzas tenemos precisamente la covarianza de los elementos i y j tal que i $\\neq$ j.\n",
    "- *Cálculo de autovalores y autovectores de la matriz de covarianzas*. \n",
    "- *Ordenación de los autovalores*. La primera de las componentes explica mayor varianza que la segunda (su autovalor es mayor), la segunda explica más que la tercera y así sucesivamente \n",
    "- *Cálculo de las componentes principales*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ff14d",
   "metadata": {},
   "source": [
    "**Vatriables a utilizar**\n",
    "- *X_train_oversampled*: Dataset de training con la técnica de oversampling sin la variable respuesta \n",
    "- *x_test*: Dataset de testing sin la variable target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7532dff",
   "metadata": {},
   "source": [
    "**Librerias a utilizar**\n",
    "- PCA de sklearn.decomposition \n",
    "- Matplotlib.pyplot\n",
    "- Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a63170",
   "metadata": {},
   "source": [
    "**Importante**: En el algoritmo de PCA necesitamos que las variables estén escaladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b24180",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "pca.fit(X_train_oversampled)\n",
    "X_train_pca = pca.transform(X_train_oversampled)\n",
    "X_test_pca = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "threshold = 0.8\n",
    "plt.figure(figsize=(12, 6), dpi=80)\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.axhline(y=threshold, color='r', linestyle='-')\n",
    "\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffdc6bc",
   "metadata": {},
   "source": [
    "Una vez podemos ver el gráfico con la línea de corte marcada en 0.8, decidimos tomar 8 componentes principales. Para obtenerlas deberemos repetir el proceso indicando al PCA que tomaremos 8 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=8)\n",
    "\n",
    "pca_2.fit(X_train_oversampled)\n",
    "X_train_pca_2 = pca_2.transform(X_train_oversampled)\n",
    "X_test_pca_2 = pca_2.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_2 = pd.DataFrame(X_train_pca_2)\n",
    "X_test_pca_2 = pd.DataFrame(X_test_pca_2)\n",
    "X_train_pca_2.columns = ['PCA_'+str(i) for i in X_train_pca_2.columns]\n",
    "X_test_pca_2.columns = ['PCA_'+str(i) for i in X_test_pca_2.columns]\n",
    "X_train_pca_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e1e08",
   "metadata": {},
   "source": [
    "Estos nuevos conjuntos de training y testing nos servirá para hacer uso de ellos en los modelos y después comparar resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f08888",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c0d47",
   "metadata": {},
   "source": [
    "# MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63754ff3",
   "metadata": {},
   "source": [
    "Antes de adentrarnos en los modelos, debemos fijar una serie de conceptos. Por un lado, hablemos de la *matriz de confusión*, de las *métricas* y de la *curva de ROC*.\n",
    "\n",
    "**Matriz de confusión**. Las matrices de confusión se utilizan en problemas de clasificación. Cada columna de la matriz representa el número de predicciones de cada clase (en nuestro caso si habrá algún fallecido o no), mientras que cada fila representa lo ocurrido realmente. Esto es, en términos prácticos nos permite ver  qué tipos de aciertos y errores está teniendo nuestro modelo a la hora de pasar por el proceso de aprendizaje con los datos.\n",
    "\n",
    "**Métricas**. Las métricas sirven para determinar el rendimiento de un modelo y, existen muchos tipos de métricas. Muchas de ellas se basan en las matrices de confusión.\n",
    "\n",
    "**Curva de ROC**. La curva de ROC es la representación gráfica de la sensibilidad(recall) frente a la especificidad. Una métrica muy conocida es el área bajo la curva de roc. Esta medida toma valores entre 1 y 0.5. Esta métrica puede interpretarse como la probabilidad de que ante un par de individuos, uno fallecido y el otro no, la prueba los clasifique correctamente.\n",
    "\n",
    "Estas son dos de las grandes cosas en las que nos tenemos que fijar para determinar la eficacia de nuestro modelo. En nuestro caso, debemos tener en cuenta que nuestro dataset es un dataset desvalanceado y, por ello, no tiene sentido tomar todas las métricas igual de importantes. Es por ello, que para este proyecto, en las métricas que más nos fijaremos serán el *recall*, *la curva de roc y el área bajo su curva* y, por supuesto *la matriz de confusión normalizada*. ¿Por qué elegimos el recall? Teniendo en cuenta que nuestro objetivo es predecir los fallecimientos de la mejor manera posible, esta medida será una de las más importantes ya que es la división entre los fallecidos acertados correctamente y el total de fallecidos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e6580",
   "metadata": {},
   "source": [
    "## MODELO GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e0e00",
   "metadata": {},
   "source": [
    "Los modelos GLM o modelos lineales generalizados, como bien su nombre indica, son una generalización de los modelos de regresión lineal. Estos modelos aparecen en el momento que la variable target no es normal. \n",
    "\n",
    "**Observación.** Recordemos que una de las condiciones de las regresiones lineales simples y múltiples es que la variable target debe ser normal.\n",
    "\n",
    "Por ello, si queremos predecir el número de personas que entrará a una tienda o si queremos predecir si alguien tiene una enfermedad o no, debemos hacer uso de los GLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45533af6",
   "metadata": {},
   "source": [
    "Para poder predecir diferentes variables target, no normales, lo que hacemos es usar una *función de link* que sea invertible, de tal forma que:\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "$g(E(Y|X)) = w_{0} + w_{1}*x_{1} + w_{2}*x_{2} + ... + w_{n}*x_{n}$\n",
    "    \n",
    "Esto se resume en que si, por ejemplo queremos que nuestra variable target sea una probabilidad, por ejemplo podemos hacer uso de la función *logit*, la cual se define de la siguiente forma:\n",
    "    \n",
    "<p style=\"text-align: center;\">\n",
    "$logit(p) = \\dfrac{p}{1-p}$, donde $p$ es la probabilidad de éxito\n",
    "\n",
    "Así, utilizando esta función, tendríamos la siguiente ecuación:\n",
    "        \n",
    "<p style=\"text-align: center;\">\n",
    "$logit(p(X)) = w_{0} + w_{1}*x_{1} + w_{2}*x_{2} + ... + w_{n}*x_{n}$\n",
    "    \n",
    "Y despejando p(X) tenemos:\n",
    "    \n",
    "<p style=\"text-align: center;\">\n",
    "$p(X) = \\dfrac{e^{w_{0} + w_{1}*x_{1} + w_{2}*x_{2} + ... + w_{n}*x_{n}}}{1 + e^{w_{0} + w_{1}*x_{1} + w_{2}*x_{2} + ... + w_{n}*x_{n}}}$   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae29ed39",
   "metadata": {},
   "source": [
    "Nosotros utilizaremos un caso particular de glm que es la *regresión logística*. En esta regresión, la función link de la que se hace uso es, por ejemplo, la función logit presentada anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3672c",
   "metadata": {},
   "source": [
    "### Regresión logística con todas las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201a9aad",
   "metadata": {},
   "source": [
    "**Vatriables a utilizar**\n",
    "- *X_train_oversampled*: Dataset de training con la técnica de oversampling sin la variable respuesta \n",
    "- *y_train_oversampled*: Variable objetivo con la técnica de oversampling (training)\n",
    "- *x_test*: Dataset de testing codificada mediante one hot encoding\n",
    "- *ytest*: Variable objetivo (dataset de testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0750ac9",
   "metadata": {},
   "source": [
    "**Librerias a utilizar**\n",
    "- LogisticRegression de sklearn.linear_model \n",
    "- Sklearn.metrics \n",
    "- Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2930d0",
   "metadata": {},
   "source": [
    "Primero hacemos el modelo con todas las variables que tenemos en el dataset. Después, realizaremos otra vez el modelo pero sólamente utilizando las variables que nos proporciona Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_LOGREG, final_LOGREG, prediction_LOGREG, predictions_proba_LOGREG, LOGREG = modelos(X_train_oversampled, y_train_oversampled, x_test, sklearn.linear_model.LogisticRegression(), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec445c2b",
   "metadata": {},
   "source": [
    "El modelo de regresión logística vemos que mejora notablemente el modelo base que hemos obtenido antes.  Pero todavía se queda lejos de predecir bien los fallecimientos y, nosotros, como aseguradora, es nuestro principal interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "medidas(ytest, prediction_LOGREG, predictions_proba_LOGREG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2f8af",
   "metadata": {},
   "source": [
    "La regresión logística mediante Lasso no ha podido ser calculada debido a que ha habido un problema con el notebook de los modelos y hemos tenido que ejecutar todo de nuevo y, la segunda parte de Lasso no ha podido ser calculada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accaeff1",
   "metadata": {},
   "source": [
    "### Regresión logística con selección de variables de Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e03f0",
   "metadata": {},
   "source": [
    "En esta ocacasión haremos uso de las variables seleccionadas en la penalización Lasso y, comprobaremos si el modelo de regresión logística ha mejorado o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45324491",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_LOGREG_LASSO, final_LOGREG_LASSO, prediction_LOGREG_LASSO, predictions_proba_LOGREG_LASSO, LOGREG_LASSO= modelos(X_train_oversampled[selected_feat_lasso], y_train_oversampled, x_test[selected_feat_lasso], sklearn.linear_model.LogisticRegression(), ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0168d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "medidas(ytest, prediction_LOGREG, predictions_proba_LOGREG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a26a3",
   "metadata": {},
   "source": [
    "##### CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d2f68",
   "metadata": {},
   "source": [
    "Los resultados del modelo de regresión logística no son malos si los comparamos con los obtenidos en el modelo base. Sin embargo, los modelos fallan mucho a la hora de intentar acertar los fallecidos y eso no nos interesa ya que buscamos el mayor número de aciertos posible en los individuos de la clase 0, es decir la clase de los fallecidos.\n",
    "\n",
    "En cuanto a los tiempos de ejecución, éstos se muestran a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f401a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_LOGREG = [start_LOGREG, final_LOGREG]\n",
    "time_LOGREG_LASSO = [start_LOGREG_LASSO, final_LOGREG_LASSO]\\n\n",
    "data_time_LOGREG = {\"LOGREG\": time_LOGREG, \"LOGREG_LASSO\":time_LOGREG_LASSO}\n",
    "time_LOGREG = pd.DataFrame(data_time_LOGREG, columns=[\"LOGREG\", \"LOGREG_LASSO\"])\n",
    "time_LOGREG.index=[\"start\", \"end\"]\n",
    "time_LOGREG = time_LOGREG.transpose()\n",
    "time_LOGREG[\"total_time(s)\"] = time_LOGREG[\"end\"]-time_LOGREG[\"start\"]\n",
    "time_LOGREG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a1ce09",
   "metadata": {},
   "source": [
    "Podemos comprobar que los tiempos de ejecución son muy parecidos pero, el tiempo de ejecución cuando hacemos uso de la importancia de variables proporcionada por Lasso, éste se reduce ligeramente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50840133",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939668a",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2660c0",
   "metadata": {},
   "source": [
    "**Def.** SVM (Supported Vector Machine) es un algoritmo tanto de clasificación como de regresión. El SVM sirve para poder separar las clases mediante un hiperplano. En dos dimensiones la separación se hace con una recta, en tres co un plano y en una dimensión n, mediante un hiperplano de dimensión n-1.\n",
    "\n",
    "**Ejemplo.** A continuación mostramos una figura como ejemplo del objetivo del algoritmo SVM en dos dimensiones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d34fa",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../Images/SVM.png\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb549487",
   "metadata": {},
   "source": [
    "Como se puede observar, el principal objetivo del SVM es separar las dos clases de tal forma que las bolas rojas queden a un lado del hiperplano (recta en este caso) y las bolas azules al otro lado del hiperplano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d179d",
   "metadata": {},
   "source": [
    "**Vatriables a utilizar**\n",
    "- *X_train_oversampled*: Dataset de training con la técnica de oversampling sin la variable respuesta \n",
    "- *y_train_oversampled*: Variable target con la técnica de oversampling\n",
    "- *x_test*: Dataset de testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba6908",
   "metadata": {},
   "source": [
    "**Librerias a utilizar**\n",
    "- SVC from sklearn.svm \n",
    "- Sklearn.metrics "
   ]
  },
  {
   "cell_type": "raw",
   "id": "34ede2d5",
   "metadata": {},
   "source": [
    "start_SVM, final_SVM, prediction_SVM, predictions_proba_SVM, SVM = modelos(X_train_oversampled, y_train_oversampled, x_test, SVC(kernel='linear'), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb7a67",
   "metadata": {},
   "source": [
    "El modelo SVM no ha podido ejecutarse ya que ha estado apróximadamente unas 19 horas en ejecución y hemos tenido que detenerlo por falta de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998df7a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b21019",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec67f3",
   "metadata": {},
   "source": [
    "Antes de conocer el algoritmo de Random Forest, será necesario conocer primero los algoritmos de árboles de decisión.\n",
    "\n",
    "**Def.** Los algoritmos de árboles de decisión, como bien su nombre indica, se basan en la representación de árbol donde cada nodo indica una variable y se separa en diferentes condiciones. Por ejemplo, si tengo una variable que me indica si una persona tiene coche o no, en el nodo de dicha variable el algoritmo se preguntará si tiene coche o no y en función de su respuesta recorrerá un camino u otro. \n",
    "\n",
    "Una representación de un árbol de decisión es la que se ve a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523579ca",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../Images/decision_tree.png\" width=\"490\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88dc6e9",
   "metadata": {},
   "source": [
    "**def.** El algoritmo de Random Forest es un algoritmo basado en árboles de decisión que sirve para resolver problemas de clasificación y de regresión. Este algoritmo es un claro ejemplo de técnica de ensamble de modelos. En otras palabras, Random Forest es el resultado de una combinación de modelos.\n",
    "\n",
    "A la hora de hacer el ensamble existen dos grandes técnicas. Tenemos el ensamble por *bagging* y el ensamble por *boosting*. El algoritmo Random Forest es un ejemplo de técnica de bagging. Ahora bien, ¿en qué consiste la técnica de bagging? Esta técnica trata de seleccionar, de manera aleatoria, muestras y crear modelos un número finito de veces. De esta manera, si seleccionamos n muestras y creamos n modelos con todas las muestras y después combinamos los n modelos, estamos haciendo *bagging*.\n",
    "\n",
    "En nuestro caso, trataremos el algoritmo RF como técnica de clasificación ya que lo que buscamos es predecir si un accidente tendrá o no fallecidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b586d5e",
   "metadata": {},
   "source": [
    "**Librerias a utilizar**\n",
    "- RandomForestClassifier from sklearn.ensemble\n",
    "- Sklearn.metrics \n",
    "- Matplotlib.pyplot\n",
    "- Seaborn\n",
    "- Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c75272",
   "metadata": {},
   "source": [
    "Puesto que nuestro objetivo es intentar predecir el número de fallecidos que habrá en un accidente (valor 0 en nuestra variable target), dado que el RF tiene un parámetro que se conoce por *class_weight*, vamos a crear un bucle en el que variaremos el peso del valor 0 en nuestra variable target para ver cuál de todos nos produce una mejor matriz de confusión y mejores valores en las métricas.\n",
    "\n",
    "Después, utilizaremos ese valor óptimo del bucle para ver los modelos RF con y sin PCA y después comparar resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060a567",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in np.arange(3, 5, 0.5):\n",
    "    RF = RandomForestClassifier(n_estimators=100, class_weight={0:i, 1:0.05}, random_state=42)\n",
    "    RF.fit(X_train_oversampled, y_train_oversampled)\n",
    "    prediccion_Random_Forest = RF.predict(x_test)\n",
    "    predictions_proba_RF = RF.predict_proba(x_test)\n",
    "    cm = confusion_matrix(ytest, prediccion_Random_Forest)\n",
    "    cm_norm = confusion_matrix(ytest, prediccion_Random_Forest, normalize=\"true\")\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    plt.title(\"Confusion matrix\")\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm_norm, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    print(\"Las métricas para i= \", i, \"son:\")\n",
    "    print(medidas(ytest, prediccion_Random_Forest, predictions_proba_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d5157",
   "metadata": {},
   "source": [
    "Podemos comprobar que la diferencia es mínima, luego, no merece la pena hacer uso de este hiperparámetro en nuestros modelos de RandomForest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779f777",
   "metadata": {},
   "source": [
    "### RANDOM FOREST SIN PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b402a",
   "metadata": {},
   "source": [
    "**Variables a utilizar:**\n",
    "- *X_train_oversampled*: Dataset de training con la técnica de oversampling sin la variable respuesta \n",
    "- *y_train_oversampled*: Parte del training de la variable respuesta\n",
    "- *x_test*: Dataset de testing\n",
    "- *ytest*: Variable objetivo (dataset de testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_RF, final_RF, prediction_RF, predictions_proba_RF, RF=modelos(X_train_oversampled, y_train_oversampled, x_test, RandomForestClassifier(random_state=42), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0404468c",
   "metadata": {},
   "source": [
    "Nuestro modelo clava los individuos de la clase 1 pero no los de la clase 0 (son quienes nos interesan), luego, deberemos modificar este modelo para que acierte más los individuos de la clase 0. ¿Cómo lo haremos? Lo conseguiremos considerando el threshold óptimo que nos proporciona la curva de ROC. Pero, ¿qué quiere decir esto que acabamos de decir? Debemos tener en cuenta que, el algoritmo, por defecto nos devuelve una probabilidad como predicción. Luego, el propio algoritmo se encarga de decidir a qué clase pertenece cada predicción en función de la probabilidad. Y, esta probabilidad, por defecto es 0.5. Esto quiere decir que, si la probabilidad devuelta por el algoritmo para un individuo i es mayor que 0.5, lo clasifica como de la clase 1, mientras que si por el contrario es menor o igual que 0.5, lo clasifica como de la clase 0. Luego, este umbral lo tenemos que introducir nosotros manualmente para que el problema sea real, puesto que no siempre es interesante que se divida en el valor 0.5. Y este umbral (o también conocido como threshold) nos lo dará la curva de ROC.\n",
    "\n",
    "LA curva de ROC, como hemos explicado antes, es la representación gráfica del recall frente a la especificidad y lo que nos interesa es encontrar el punto óptimo entre recall y sensitividad. Ese punto óptimo será nuestro threshold. Veamos a continuación como podemos calcularlo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bfe17d",
   "metadata": {},
   "source": [
    "##### THRESHOLD ÓPTIMO MEDIANTE LA CURVA DE ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f681d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_RF = predictions_proba_RF[:, 1]\n",
    "fpr_RF, tpr_RF, thresholds_RF = roc_curve(ytest, yhat_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans_RF = np.sqrt(tpr_RF * (1-fpr_RF))\n",
    "ix_RF = np.argmax(np.sqrt(tpr_RF * (1-fpr_RF)))\n",
    "predictions_roc_RF=(predictions_proba_RF[:,1] >= thresholds_RF[ix_RF]).astype(int)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds_RF[ix_RF], gmeans_RF[ix_RF]))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr_RF, tpr_RF, marker='.', label='Random Forest')\n",
    "plt.scatter(fpr_RF[ix_RF], tpr_RF[ix_RF], s=100, marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7fe61",
   "metadata": {},
   "source": [
    "Para nuestro modelo, el threshold óptimo se da en 0.98. Luego, con el vector de predicciones nuevo calculado, volvemos a sacar las matrices de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889d431",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm_RF_roc = confusion_matrix(ytest, predictions_roc_RF)\n",
    "cm_norm_RF_roc = confusion_matrix(ytest, predictions_roc_RF, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_RF_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_norm_RF_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e2a29",
   "metadata": {},
   "source": [
    "El rendimiento del modelo ha incrementado notablemente al considerar las nuevas predicciones que hemos calculado mediante el threshold óptimo. Tenemos un total de aciertos en fallecidos de casi el 75%, lo cual no es del todo una mala cifra. Veamos los resultado numéricos analizando los resultados de las diferentes métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a21370",
   "metadata": {},
   "source": [
    "##### MÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1cd5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "medidas(ytest, predictions_roc_RF, predictions_proba_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852364e8",
   "metadata": {},
   "source": [
    "Si nos fijamos en las métricas recall y roc_score, podemos observar que tanto el roc_score como el recall no tienen malos valores. El recall está cercano a 0.8 y el roc_score cercano a 0.85. Luego, de momento, este modelo parece el mejor entre los que hemos analizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b0297",
   "metadata": {},
   "source": [
    "Ahora, guardamos el modelo en un formato pickle con el nombre *RF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/RF.pickle', 'wb') as f:\n",
    "    pickle.dump(RF, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8464c",
   "metadata": {},
   "source": [
    "Ahora, vamos a plantear el mismo algoritmo de RF pero únicamente introduciendo las componentes obtenidas en el PCA. Después, compararemos los resultados obtenidos y finalmente, decidiremos si merece la pena introducir el PCA en el algoritmo RF o no."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64303a",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CON PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7fb399",
   "metadata": {},
   "source": [
    "**Variables a utilizar:**\n",
    "- *X_train_pca_2*: Dataset de training obtenido con la técnica de selección de variables PCA \n",
    "- *y_train_oversampled*: Parte del training de la variable respuesta\n",
    "- *X_test_pca_2*: Dataset de testing obtenido con la técnica de seleccioón de variables PCA \n",
    "- *ytest*: Variable objetivo (dataset de testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_RF_PCA, final_RF_PCA, prediction_RF_PCA, predictions_proba_RF_PCA, RF_PCA= modelos(X_train_pca_2, y_train_oversampled, X_test_pca_2, RandomForestClassifier(random_state=42), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ecc7c",
   "metadata": {},
   "source": [
    "##### THRESHOLD ÓPTIMO MEDIANTE LA CURVA DE ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_RF_PCA = predictions_proba_RF_PCA[:, 1]\n",
    "fpr_RF_PCA, tpr_RF_PCA, thresholds_RF_PCA = roc_curve(ytest, yhat_RF_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans_RF_PCA = np.sqrt(tpr_RF_PCA * (1-fpr_RF_PCA))\n",
    "ix_RF_PCA = np.argmax(np.sqrt(tpr_RF_PCA * (1-fpr_RF_PCA)))\n",
    "predictions_roc_RF_PCA=(predictions_proba_RF_PCA[:,1] >= thresholds_RF_PCA[ix_RF_PCA]).astype(int)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds_RF_PCA[ix_RF_PCA], gmeans_RF_PCA[ix_RF_PCA]))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr_RF_PCA, tpr_RF_PCA, marker='.', label='Random Forest')\n",
    "plt.scatter(fpr_RF_PCA[ix_RF_PCA], tpr_RF_PCA[ix_RF_PCA], s=100, marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5831a2",
   "metadata": {},
   "source": [
    "Repetimos las matrices de confusión considerando el threshold ofrecido por la curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_RF_PCA_roc = confusion_matrix(ytest, predictions_roc_RF_PCA)\n",
    "cm_norm_RF_PCA_roc = confusion_matrix(ytest, predictions_roc_RF_PCA, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_RF_PCA_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_norm_RF_PCA_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaac6ee",
   "metadata": {},
   "source": [
    "Las matrices de confusión han mejorado, como era de esperar, hasta llegar a un 75% de aciertos para los individuos de la clase 0. Sin embargo, si comparamos las matrices obtenidas con el RF sin PCA y estas, podemos observar que las matrices del primer modelo son bastante mejores que estas, es por ello que se concluye que no merece la pena utilizar el PCA en este caso. Después veremos los tiempos de ejecución para comparar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759168b",
   "metadata": {},
   "source": [
    "Veamos las métricas de este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe5f11",
   "metadata": {},
   "source": [
    "##### MÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b675b328",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "medidas(ytest, predictions_roc_RF_PCA, predictions_proba_RF_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c147d",
   "metadata": {},
   "source": [
    "Se demuestra lo mencionado anteriormente, tanto el recall como el área bajo la curva ROC son menores que en el primer modelo. Luego, el primer modelo supera al RF con PCA en términos de resultados. Veamos qué ocurre con el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62cfa1d",
   "metadata": {},
   "source": [
    "Ahora, guardamos el modelo en un formato pickle con el nombre *RF_PCA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/RF_PCA.pickle', 'wb') as f:\n",
    "    pickle.dump(RF_PCA, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4fc3e",
   "metadata": {},
   "source": [
    "Una vez tenemos ambos resultados, podemos concluir que merece la pena "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c04135",
   "metadata": {},
   "source": [
    "##### CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335dd15c",
   "metadata": {},
   "source": [
    "Primeramente, los tiempos de ejecución para ambos modelos es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074dbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_RF = [start_RF, final_RF]\n",
    "time_RF_PCA = [start_RF_PCA, final_RF_PCA]\n",
    "data_time_RF = {\"RF\": time_RF, \"RF_PCA\":time_RF_PCA}\n",
    "time_RF = pd.DataFrame(data_time_RF, columns=[\"RF\", \"RF_PCA\"])\n",
    "time_RF.index=[\"start\", \"end\"]\n",
    "time_RF = time_RF.transpose()\n",
    "time_RF[\"total_time(s)\"] = time_RF[\"end\"]-time_RF[\"start\"]\n",
    "time_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190a297",
   "metadata": {},
   "source": [
    "En términos de cómputo, resulta curioso que en este caso el modelo que más ha tardado ha sido el modelo en el que hacemos uso de PCA y la diferencia es bastante grande, casi el doble. Además, hemos podido comprobar que el RandomForest nos ha proporcionado mejores resultados, debido a que acierta bastante bien los accidentes de la clase 0 y muestra buenísimos resultados con los individuos de la clase 1. Luego, claramente el modelo con el que nos quedamos es el guardado con el nombre RF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c7d29",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a224e",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa374dc",
   "metadata": {},
   "source": [
    "**Def.** El algoritmo XGBBoost, al igual que el Random Forest, es un algoritmo de ensamble basado en árboles de decisión. \n",
    "\n",
    "Este algoritmo también hace uso de la técnica de ensamblaje pero lo hace mediante boosting. ¿En qué consiste el boosting? En bagging, todos los datos tienen la misma probabilidad de ser elegidos en cada iteración. Sin embargo, en boosting no ocurre esto. Esto se resume en que la técnica de boosting insiste más en lo que más se falla. En otras palabras, en cada iteración, este algoritmo asigna una serie de pesos a cada punto del dataset, en función de los fallos que encuentre en la iteración anterior.\n",
    "\n",
    "Esto puede tener ventajas y desventajas frente al random forest. La gran ventaja es que es más preciso pero, la mayor desventaja es el tiempo de ejecución ya que XGBoost no puede empezar con la siguiente iteración sin haber acabado la anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2697d83",
   "metadata": {},
   "source": [
    "**Librerias a utilizar**\n",
    "- Xgboost as xgb\n",
    "- Sklearn.metrics\n",
    "- XGBClassifier from xgboost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e34dd3",
   "metadata": {},
   "source": [
    "### XGBOOST SIN PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f959dc7",
   "metadata": {},
   "source": [
    "**Variables a utilizar:**\n",
    "- *X_train_oversampled*: Dataset de training con la técnica de oversampling sin la variable respuesta \n",
    "- *y_train_oversampled*: Parte del training de la variable respuesta\n",
    "- *x_test*: Dataset de testing modificado con la función de escalado\n",
    "- *ytest*: Variable objetivo (dataset de testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ec4e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_XGB, final_XGB, prediction_XGB, predictions_proba_XGB, XGB= modelos(X_train_oversampled, y_train_oversampled, x_test, XGBClassifier(), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd57388",
   "metadata": {},
   "source": [
    "A primera vista, el modelo es realmente malo. Luego, para mejorar el rendimiento del mismo, deberemos calcular el threshold óptimo mediante la curva de ROC al igual que lo hemos hecho para los casos de RandomForest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91dc9c1",
   "metadata": {},
   "source": [
    "##### THRESHOLD ÓPTIMO MEDIANTE LA CURVA DE ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c696aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_XGB = predictions_proba_XGB[:, 1]\n",
    "fpr_XGB, tpr_XGB, thresholds_XGB = roc_curve(ytest, yhat_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ace05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans_XGB = np.sqrt(tpr_XGB * (1-fpr_XGB))\n",
    "ix_XGB = np.argmax(np.sqrt(tpr_XGB * (1-fpr_XGB)))\n",
    "predictions_roc_XGB=(predictions_proba_XGB[:,1] >= thresholds_XGB[ix_XGB]).astype(int)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds_XGB[ix_XGB], gmeans_XGB[ix_XGB]))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr_XGB, tpr_XGB, marker='.', label='XGB')\n",
    "plt.scatter(fpr_XGB[ix_XGB], tpr_XGB[ix_XGB], s=100, marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0526055",
   "metadata": {},
   "source": [
    "##### MATRICES DE CONFUSIÓN CON THRESHOL ÓPTIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e3622",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_XGB_roc = confusion_matrix(ytest, predictions_roc_XGB)\n",
    "cm_norm_XGB_roc = confusion_matrix(ytest, predictions_roc_XGB, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_XGB_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_norm_XGB_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab8e19",
   "metadata": {},
   "source": [
    "Vemos como el modelo ha cambiado completamente. Acertamos más que antes, pero seguimos estando lejos del objetivo de predecir los fallecidos ya que fallamos demasiado. Es por ello que, viendo el modelo de RandomForest que hemos obtenido anteriormente, este modelo no nos dice gran cosa. Veamos cuáles son los valores de las métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf82d2f",
   "metadata": {},
   "source": [
    "##### MÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0042d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "medidas(ytest, prediction_XGB, predictions_proba_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a9964",
   "metadata": {},
   "source": [
    "Ahora, guardamos el modelo en un formato pickle con el nombre *XGB*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/XGB.pickle', 'wb') as f:\n",
    "    pickle.dump(XGB, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc93ee",
   "metadata": {},
   "source": [
    "Veamos qué ocurre con el mismo modelo XGBoost pero, haciendo uso del PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c9ba9",
   "metadata": {},
   "source": [
    "### XGBOOST CON PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611f7f8",
   "metadata": {},
   "source": [
    "**Variables a utilizar:**\n",
    "- *X_train_pca_2*: Dataset de training obtenido con la técnica de selección de variables PCA \n",
    "- *y_train_oversampled*: Parte del training de la variable respuesta\n",
    "- *X_test_pca_2*: Dataset de testing obtenido con la técnica de seleccioón de variables PCA \n",
    "- *ytest*: Variable objetivo (dataset de testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4152ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_XGB_PCA, final_XGB_PCA, prediction_XGB_PCA, predictions_proba_XGB_PCA, XGB_PCA= modelos(X_train_pca_2, y_train_oversampled, X_test_pca_2, XGBClassifier(), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251714a6",
   "metadata": {},
   "source": [
    "La mtriz de confusión que se obtiene tiene una mejor forma que la que hemos obtenido antes al ejecutar el XGBoost sin PCA y sin el threshold de ROC. La mejor forma se debe a que acertamos más los fallecidos que antes. Sin embargo, introduzcamos el threshold de ROC para ver si el modelo puede llegar a superar al de RandomForest obtenido anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9863984",
   "metadata": {},
   "source": [
    "##### THRESHOLD ÓPTIMO MEDIANTE LA CURVA DE ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff440781",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_XGB_PCA = predictions_proba_XGB_PCA[:, 1]\n",
    "fpr_XGB_PCA, tpr_XGB_PCA, thresholds_XGB_PCA = roc_curve(ytest, yhat_XGB_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans_XGB_PCA = np.sqrt(tpr_XGB_PCA * (1-fpr_XGB_PCA))\n",
    "ix_XGB_PCA = np.argmax(np.sqrt(tpr_XGB_PCA * (1-fpr_XGB_PCA)))\n",
    "predictions_roc_XGB_PCA=(predictions_proba_XGB_PCA[:,1] >= thresholds_XGB_PCA[ix_XGB_PCA]).astype(int)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds_XGB_PCA[ix_XGB_PCA], gmeans_XGB_PCA[ix_XGB_PCA]))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr_XGB_PCA, tpr_XGB_PCA, marker='.', label='XGB_PCA')\n",
    "plt.scatter(fpr_XGB_PCA[ix_XGB_PCA], tpr_XGB_PCA[ix_XGB_PCA], s=100, marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5730cf",
   "metadata": {},
   "source": [
    "Repetimos las matrices de confusión considerando el threshold ofrecido por la curva roc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_XGB_PCA_roc = confusion_matrix(ytest, predictions_roc_XGB_PCA)\n",
    "cm_norm_XGB_PCA_roc = confusion_matrix(ytest, predictions_roc_XGB_PCA, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_XGB_PCA_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_norm_XGB_PCA_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35328f5",
   "metadata": {},
   "source": [
    "Analizando las matrices, y fijándonos en la que más información nos proporciona que es la normalizada, vemos que el modelo ha mejorado con respecto al XGBoost sin PCA en el ámbito de acierto de fallecidos, pero con una probabilidad de casi un 70% todavía nos seguimso quedando con el mejor modelo hasta ahora, el RandomForest. Veamos las métricas de nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a517cf8",
   "metadata": {},
   "source": [
    "##### MÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3a4ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "medidas(ytest, predictions_roc_XGB_PCA, predictions_proba_XGB_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51a166",
   "metadata": {},
   "source": [
    "......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461b145",
   "metadata": {},
   "source": [
    "Guardamos el modelo en formato pickle con el nombre de *XGB_PCA*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c682af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/XGB_PCA.pickle', 'wb') as f:\n",
    "    pickle.dump(XGB_PCA, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391c944",
   "metadata": {},
   "source": [
    "##### CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115068ee",
   "metadata": {},
   "source": [
    "En primer lugar, mostraremos los tiempos de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93de9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_XGB = [start_XGB, final_XGB]\n",
    "time_XGB_PCA = [start_XGB_PCA, final_XGB_PCA]\n",
    "data_time_XGB = {\"XGB\": time_XGB, \"XGB_PCA\":time_XGB_PCA}\n",
    "time_XGB = pd.DataFrame(data_time_XGB, columns=[\"XGB\", \"XGB_PCA\"])\n",
    "time_XGB.index=[\"start\", \"end\"]\n",
    "time_XGB = time_XGB.transpose()\n",
    "time_XGB[\"total_time(s)\"] = time_XGB[\"end\"]-time_XGB[\"start\"]\n",
    "time_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe5eb9",
   "metadata": {},
   "source": [
    "Los tiempos de ejecución rondan los 6 minutos para el modelo XGboost y los 5 minutos para el modelo XGBoost con PCA. Como era de esperar, el tiempo de ejecución para PCA es mejor ya que introducimos un número reducido de variables. Además, hemos comprobado que el XGBoost con PCA nos proporciona mejores resultados, teniendo en cuenta nuestro objetivo, que el XGBoost. Luego, en este caso, merece la pena considerar el modelo de XGBoost con PCA.\n",
    "\n",
    "Sin embargo, comparando el mejor modelo obtenido con el algoritmo de boosting XGBoost, no alcanzamos al modelo RandomForest que hemos mostrado antes. Luego, deberemos descartar el algoritmo XGBoost para nuestro problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e627b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bb5df",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a59489",
   "metadata": {},
   "source": [
    "**def**. Light GBM, al igual que el XGBoost, es un algoritmo de boosting que se basa en árboles de decisión. A diferencia de los algoritmos vistos anteriormente, los árboles en Light GBM crecen de manera vertical. La decisión de ir creciendo la va tomando en función a "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b3558",
   "metadata": {},
   "source": [
    "Por esa misma razón, este algoritmo está más optimizado que el XGBoost ya que su velocidad de entrenamiento es mayor. A continuación mostramos una ilustración en la que podemos apreciar la diferencia entre el crecimiento de algoritmos como XGBoost y el crecimiento del algoritmo Light GBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0c3c",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../Images/LightGBM_crecimiento.png\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbfec20",
   "metadata": {},
   "source": [
    "**Librerias a utilizar**\n",
    "- Lightgbm\n",
    "- Sklearn.metrics\n",
    "- Matplotlib.pyplot\n",
    "- Pandas\n",
    "- Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaaa02c",
   "metadata": {},
   "source": [
    "### LIGHT GBM SIN PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed622d",
   "metadata": {},
   "source": [
    "**Variables a utilizar:**\n",
    "- *X_train_oversampled*: Dataset de training con la técnica de oversampling sin la variable respuesta \n",
    "- *y_train_oversampled*: Parte del training de la variable respuesta\n",
    "- *x_test*: Dataset de testing modificado con la función de escalado\n",
    "- *ytest*: Variable objetivo (dataset de testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f7464",
   "metadata": {},
   "source": [
    "Haciendo uso de la función *modelos*, calculamos el tiempo inicial, final, la predicción normal y la probabilística y también el modelo entrenado, para así después, poder guardarlo en formato pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91cccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_LGBM, final_LGBM, prediction_LGBM, predictions_proba_LGBM, LGBM = modelos(X_train_oversampled, y_train_oversampled, x_test, lgb.LGBMClassifier(random_state=42), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa3d81",
   "metadata": {},
   "source": [
    "De igual forma que nos ha ocurrido con XGBoost, los resultados que obtenemos al ejecutar el modelo son malos. Todos las predicciones se nos van a la clase 1, es decir, a los no fallecidos. La curva de ROC y la de ganancia ......\n",
    "\n",
    "Puesto que todavía estamos lejos de nuestro objetivo, planteamos el mismo modelo pero considerando el threshold óptimo que nos proporciona la curva de ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6adae9a",
   "metadata": {},
   "source": [
    "##### THRESHOLD ÓPTIMO MEDIANTE LA CURVA DE ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5fcf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_LGBM = predictions_proba_LGBM[:, 1]\n",
    "fpr_LGBM, tpr_LGBM, thresholds_LGBM = roc_curve(ytest, yhat_LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b403382",
   "metadata": {},
   "source": [
    "Ahora, generamos las nuevas predicciones teniendo en cuenta nuestro nuevo threshols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans_LGBM = np.sqrt(tpr_LGBM * (1-fpr_LGBM))\n",
    "ix_LGBM = np.argmax(np.sqrt(tpr_LGBM * (1-fpr_LGBM)))\n",
    "predictions_roc_LGBM=(predictions_proba_LGBM[:,1] >= thresholds_LGBM[ix_LGBM]).astype(int)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds_LGBM[ix_LGBM], gmeans_LGBM[ix_LGBM]))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr_LGBM, tpr_LGBM, marker='.', label='LGBM')\n",
    "plt.scatter(fpr_LGBM[ix_LGBM], tpr_LGBM[ix_LGBM], s=100, marker='o', color='black', label='Best')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c41bc4",
   "metadata": {},
   "source": [
    "El threshold obtenido, como se puede comprobar, es de 0.93."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb85be",
   "metadata": {},
   "source": [
    "Repetimos las matrices de confusión considerando el nuevo vector de predicciones obtenido mediante el threshold óptimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d654396",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_LGBM_roc = confusion_matrix(ytest, predictions_roc_LGBM)\n",
    "cm_norm_LGBM_roc = confusion_matrix(ytest, predictions_roc_LGBM, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_LGBM_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_norm_LGBM_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534a1a7",
   "metadata": {},
   "source": [
    "La mejoría es notable en las matrices de confusión, como se puede apreciar, pero, al igual que con el algoritmo XGBoost, todavía falla mucho en los individuos de la clase 0, comprobemos las métricas para verlo numéricamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d449ef",
   "metadata": {},
   "source": [
    "##### MÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f28f19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "medidas(ytest, predictions_roc_LGBM, predictions_proba_LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af6e4b1",
   "metadata": {},
   "source": [
    "Parece que nuestras sospechas eran ciertas puesto que el recall y el roc_score no son valores muy elevados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a77701",
   "metadata": {},
   "source": [
    "Ahora, guardamos el modelo en un formato pickle con el nombre *LGBM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/LGBM.pickle', 'wb') as f:\n",
    "    pickle.dump(LGBM, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b882d",
   "metadata": {},
   "source": [
    "### LIGHT GBM CON PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc2494",
   "metadata": {},
   "source": [
    "**Variables a utilizar:**\n",
    "- *X_train_pca_2*: Dataset de training obtenido con la técnica de selección de variables PCA \n",
    "- *y_train_oversampled*: Parte del training de la variable respuesta\n",
    "- *X_test_pca_2*: Dataset de testing obtenido con la técnica de seleccioón de variables PCA \n",
    "- *ytest*: Variable objetivo (dataset de testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_LGBM_PCA, final_LGBM_PCA, prediction_LGBM_PCA, predictions_proba_LGBM_PCA, LGBM_PCA = modelos(X_train_pca_2, y_train_oversampled, X_test_pca_2, lgb.LGBMClassifier(random_state=42), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f14e16",
   "metadata": {},
   "source": [
    "Como podemos observar, la matriz de confusión del modelo no es nada buena. Para tener otra visión del modelo, calcularemos el threshol óptimo mediante la curva de ROC. Esto permitirá que el umbral en el que se decide que la predicción es fallecido o no fallecido cambie, y, por tanto, la matriz de confusión cambiará."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c32ac7",
   "metadata": {},
   "source": [
    "##### THRESHOLD ÓPTIMO MEDIANTE LA CURVA DE ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_LGBM_PCA = predictions_proba_LGBM_PCA[:, 1]\n",
    "fpr_LGBM_PCA, tpr_LGBM_PCA, thresholds_LGBM_PCA = roc_curve(ytest, yhat_LGBM_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e5f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans_LGBM_PCA = np.sqrt(tpr_LGBM_PCA * (1-fpr_LGBM_PCA))\n",
    "ix_LGBM_PCA = np.argmax(np.sqrt(tpr_LGBM_PCA * (1-fpr_LGBM_PCA)))\n",
    "predictions_roc_LGBM_PCA=(predictions_proba_LGBM_PCA[:,1] >= thresholds_LGBM_PCA[ix_LGBM_PCA]).astype(int)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds_LGBM_PCA[ix_LGBM_PCA], gmeans_LGBM_PCA[ix_LGBM_PCA]))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr_LGBM_PCA, tpr_LGBM_PCA, marker='.', label='LGBM_PCA')\n",
    "plt.scatter(fpr_LGBM_PCA[ix_LGBM_PCA], tpr_LGBM_PCA[ix_LGBM_PCA], s=100, marker='o', color='black', label='Best')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33263e4f",
   "metadata": {},
   "source": [
    "Una vez tenemos el vector de predicciones con la curva ROC, mostramos nuevamente la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc24a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_LGBM_PCA_roc = confusion_matrix(ytest, predictions_roc_LGBM_PCA)\n",
    "cm_norm_LGBM_PCA_roc = confusion_matrix(ytest, predictions_roc_LGBM_PCA, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_LGBM_PCA_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_norm_LGBM_PCA_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df975fc1",
   "metadata": {},
   "source": [
    "Claramente las matrices cambian y, el rendimiento del modelo no es malo del todo. Veamos ahora las métricas del modelo mediante la función *medidas*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40343deb",
   "metadata": {},
   "source": [
    "##### MÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ad240",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "medidas(ytest, predictions_roc_LGBM_PCA, predictions_proba_LGBM_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d03f92",
   "metadata": {},
   "source": [
    "Ahora, guardamos el modelo en un formato pickle con el nombre *LGBM_PCA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/LGBM_PCA.pickle', 'wb') as f:\n",
    "    pickle.dump(LGBM_PCA, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518689e",
   "metadata": {},
   "source": [
    "##### CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f5b6d",
   "metadata": {},
   "source": [
    "Los tiempos de ejecución se muestran a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ffa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_LGBM = [start_LGBM, final_LGBM]\n",
    "time_LGBM_PCA = [start_LGBM_PCA, final_LGBM_PCA]\n",
    "data_time_LGBM = {\"LGBM\": time_LGBM, \"LGBM_PCA\":time_LGBM_PCA}\n",
    "time_LGBM = pd.DataFrame(data_time_LGBM, columns=[\"LGBM\", \"LGBM_PCA\"])\n",
    "time_LGBM.index=[\"start\", \"end\"]\n",
    "time_LGBM = time_LGBM.transpose()\n",
    "time_LGBM[\"total_time(s)\"] = time_LGBM[\"end\"]-time_LGBM[\"start\"]\n",
    "time_LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7491a",
   "metadata": {},
   "source": [
    "Hemos podido comprobar que los modelos light GBM planteados (con y sin PCA) generan unos resultados muy parecidos, aunque también se pueden apreciar ligeros cambios en la matriz de confusión. El modelo Light GBM con PCA hace más incapié en los fallecimientos acertados que el modelo sin PCA. De esa manera, el modelo sin PCA acierta más en los accidentes en los que no hay fallecidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c1f6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10943b28",
   "metadata": {},
   "source": [
    "# Mejor modelo con modificación de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4c183",
   "metadata": {},
   "source": [
    "Después de haber analizado todos los modelos, hemos podido comprobar que el mejor es el RandomForest debido a su gran rendimiento en la matriz de confusión normalizada.\n",
    "\n",
    "Ahora, lo que deberemos hacer será tomar el modelo RandomForest e intentar encontrar sus hiperparámetros óptimos. Para ello, lo que se debe hacer es tomar diferentes hiperparámetros e iterar. Crear un modelo para cada uno de estos hiperparámetros que definamos y, después determinar cual es el mejor de todos los modelos.\n",
    "\n",
    "Para ello, definimos un pipeline con el modelo de RandomForest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandF = Pipeline(steps=[('classifier', RandomForestClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229152b",
   "metadata": {},
   "source": [
    "Mediante el atributo .get_params() podemos obtener todos los hiperparámetros que tiene el RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfb6a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RandF.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259d890",
   "metadata": {},
   "source": [
    "En nuestro caso, la optimización de hiperparámetros la haremos con la función RandomizedSearCV. Realizar todas las combinaciones de hiperparámetros requiere un alto coste computacional ya que estaríamos aplicando lo conocido como *fuerza bruta*. Por ello, el algoritmo RandomizedSearchCV consiste en muestrear al azar a partir de una variedad de parámetros. De esta forma, este algoritmo no prueba todas las combinaciones posibles de valores sino que sólamente un número de ellas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7df315",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'classifier__n_estimators': [20, 50, 100], \n",
    "    #'classifier__class_weight': [{0:5.1, 1:0.05}, {0:6.1, 1:0.05}, {0:7.1, 1:0.05}],\n",
    "    'classifier__max_depth' : [6,8,10, 12],\n",
    "    'classifier__criterion' :[\"gini\", \"entropy\"]}\n",
    "\n",
    "start_hiperparam=time.time()\n",
    "\n",
    "CV = RandomizedSearchCV(RandF, param_grid, cv=10, random_state=42, n_jobs=2, scoring=\"roc_auc\")\n",
    "                  \n",
    "BM = CV.fit(X_train_oversampled, y_train_oversampled)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)\n",
    "\n",
    "end_hiperparam = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd78dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_BM = CV.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0300ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_proba_BM = CV.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_Best_model = confusion_matrix(ytest, prediction_Best_model)\n",
    "cm_norm_Best_model = confusion_matrix(ytest, prediction_Best_model, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_Best_model, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_norm_Best_model, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_BM = predictions_proba_BM[:, 1]\n",
    "fpr_BM, tpr_BM, thresholds_BM = roc_curve(ytest, yhat_BM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans_BM = np.sqrt(tpr_BM * (1-fpr_BM))\n",
    "ix_BM = np.argmax(np.sqrt(tpr_BM * (1-fpr_BM)))\n",
    "predictions_roc_BM=(predictions_proba_BM[:,1] >= thresholds_BM[ix_BM]).astype(int)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds_BM[ix_BM], gmeans_BM[ix_BM]))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr_BM, tpr_BM, marker='.', label='Random Forest')\n",
    "plt.scatter(fpr_BM[ix_BM], tpr_BM[ix_BM], s=100, marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfe514",
   "metadata": {},
   "source": [
    "Una vez tenemos el vector de probabilidades actualizado con la curva de roc, hallamos la matriz de confusión óptima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_Best_model_roc = confusion_matrix(ytest, predictions_roc_BM)\n",
    "cm_norm_Best_model_roc = confusion_matrix(ytest, predictions_roc_BM, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_Best_model_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_norm_Best_model_roc, annot=True, fmt=\".3f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(\"Normalized confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\\\"El tiempo de ejecución de la optimización de hiperparámetros es: \", end_hiperparam-start_hiperparam, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888318a",
   "metadata": {},
   "source": [
    "Podemos comprobar, que aunque la optimización de hiperparámetros nos diga que es el mejor modelo que hemos encontrado, no es del todo cierto. Las mtrices de confusión que hemos obtenido para el modelo RF son bastante mejores. Luego, parece, que en nuestro caso la optimización de hiperparámetros no ha dado sus frutos y nos tenemos que quedar con el modelo RF que hemos definido anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf73568",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/BM.pickle', 'wb') as f:\n",
    "    pickle.dump(BM, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML_big_practice]",
   "language": "python",
   "name": "conda-env-ML_big_practice-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
