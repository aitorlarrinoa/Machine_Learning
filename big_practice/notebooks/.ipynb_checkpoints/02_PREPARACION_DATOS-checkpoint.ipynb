{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8b9112",
   "metadata": {},
   "source": [
    "# ANÁLISIS DE SINIESTRALIDAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b3b778",
   "metadata": {},
   "source": [
    "### CUNEF MUCD (2021/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57937ff4",
   "metadata": {},
   "source": [
    "- Aitor Larriona Rementería\n",
    "- Diego Cendán Bedregal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69660d5d",
   "metadata": {},
   "source": [
    "## LIBRERÍAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3f39a",
   "metadata": {},
   "source": [
    "Librerías básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b8f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from statistics import mode, multimode\n",
    "import time\n",
    "import sklearn\n",
    "import warnings\n",
    "import scikitplot as skplt\n",
    "import statsmodels.api as sapi\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d22a15",
   "metadata": {},
   "source": [
    "Librerías para codificar variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7a0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from category_encoders.target_encoder import TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178eb3c",
   "metadata": {},
   "source": [
    "Librerías para oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41db832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51062e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42795697",
   "metadata": {},
   "source": [
    "Librerías para separar en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb26eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a41f7",
   "metadata": {},
   "source": [
    "Importamos el pipeline y pickle (para guardar los modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0252929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda5d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa21b73",
   "metadata": {},
   "source": [
    "Importamos también las funciones necesarias en este notebook del notebook de funciones 00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0575f1ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de1aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run FUNCIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916636e1",
   "metadata": {},
   "source": [
    "## Lectura y modificación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043436c4",
   "metadata": {},
   "source": [
    "Lectura de la tabla .parquet que hemos creado en el notebook *01_EDA*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5134630",
   "metadata": {},
   "source": [
    "**Importante:** Antes de utilizar el formato parquet, se ha utilizado también la opción de escribir un csv. Sin embargo, esta opción distorsionaba los datos y no correspondían las clases del data frame pd_data en *01_EDA* con las clases del data frame que cargábamos en este notebook. Por ello, se ha optado por el formato parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b01c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table('/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big_practice_data/pd_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b571a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_YEAR</th>\n",
       "      <th>cos_C_MNTH</th>\n",
       "      <th>sin_C_MNTH</th>\n",
       "      <th>cos_C_WDAY</th>\n",
       "      <th>sin_C_WDAY</th>\n",
       "      <th>cos_C_HOUR</th>\n",
       "      <th>sin_C_HOUR</th>\n",
       "      <th>C_SEV</th>\n",
       "      <th>C_VEHS</th>\n",
       "      <th>C_CONF</th>\n",
       "      <th>C_RCFG</th>\n",
       "      <th>C_WTHR</th>\n",
       "      <th>C_RSUR</th>\n",
       "      <th>C_RALN</th>\n",
       "      <th>C_TRAF</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.682553</td>\n",
       "      <td>-0.730836</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>03</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.682553</td>\n",
       "      <td>-0.730836</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>03</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>-0.57668</td>\n",
       "      <td>0.81697</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>-0.068242</td>\n",
       "      <td>-0.997669</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>QQ</td>\n",
       "      <td>QQ</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>-0.068242</td>\n",
       "      <td>-0.997669</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>QQ</td>\n",
       "      <td>QQ</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902109</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902110</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902111</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902112</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902113</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.775711</td>\n",
       "      <td>-0.631088</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3902114 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         C_YEAR  cos_C_MNTH  sin_C_MNTH  cos_C_WDAY  sin_C_WDAY  cos_C_HOUR  \\\n",
       "0          1999    0.866025         0.5     0.62349    0.781831    0.682553   \n",
       "1          1999    0.866025         0.5     0.62349    0.781831    0.682553   \n",
       "2          1999    0.866025         0.5     0.62349    0.781831    -0.57668   \n",
       "3          1999    0.866025         0.5     0.62349    0.781831   -0.068242   \n",
       "4          1999    0.866025         0.5     0.62349    0.781831   -0.068242   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "3902109    2014        <NA>        <NA>        <NA>        <NA>        <NA>   \n",
       "3902110    2014        <NA>        <NA>        <NA>        <NA>        <NA>   \n",
       "3902111    2014        <NA>        <NA>        <NA>        <NA>        <NA>   \n",
       "3902112    2014        <NA>        <NA>        <NA>        <NA>        <NA>   \n",
       "3902113    2014        <NA>        <NA>        <NA>        <NA>   -0.775711   \n",
       "\n",
       "         sin_C_HOUR  C_SEV  C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN C_TRAF  \\\n",
       "0         -0.730836      2       2     03   None     01     02     02     01   \n",
       "1         -0.730836      2       2     03   None     01     02     02     01   \n",
       "2           0.81697      2       1     01   None     02     02     02     03   \n",
       "3         -0.997669      2       3     QQ     QQ     01     02     01     01   \n",
       "4         -0.997669      2       3     QQ     QQ     01     02     01     01   \n",
       "...             ...    ...     ...    ...    ...    ...    ...    ...    ...   \n",
       "3902109        <NA>      2    <NA>   None     01   None   None   None   None   \n",
       "3902110        <NA>      2    <NA>   None     01   None   None   None   None   \n",
       "3902111        <NA>      2    <NA>   None     01   None   None   None   None   \n",
       "3902112        <NA>      2    <NA>   None     01   None   None   None   None   \n",
       "3902113   -0.631088      2       1     01     01     01     02     02     03   \n",
       "\n",
       "         Random  \n",
       "0            98  \n",
       "1            61  \n",
       "2            22  \n",
       "3            75  \n",
       "4            16  \n",
       "...         ...  \n",
       "3902109      36  \n",
       "3902110      68  \n",
       "3902111      30  \n",
       "3902112      52  \n",
       "3902113      68  \n",
       "\n",
       "[3902114 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd_data = table.to_pandas()\n",
    "df_pd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054232e3",
   "metadata": {},
   "source": [
    "Comprobemos ahora que la clase de las variables es correcto y que no ha habido modificaciones de ningún tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75f702e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_YEAR          int64\n",
       "cos_C_MNTH    Float64\n",
       "sin_C_MNTH    Float64\n",
       "cos_C_WDAY    Float64\n",
       "sin_C_WDAY    Float64\n",
       "cos_C_HOUR    Float64\n",
       "sin_C_HOUR    Float64\n",
       "C_SEV           int64\n",
       "C_VEHS          Int64\n",
       "C_CONF         object\n",
       "C_RCFG         object\n",
       "C_WTHR         object\n",
       "C_RSUR         object\n",
       "C_RALN         object\n",
       "C_TRAF         object\n",
       "Random          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ec0df",
   "metadata": {},
   "source": [
    "Nuestro objetivo es predecir si habrá o no muertos en un accidente de tráfico. Es por ello mismo que nos quedaremos con todos los datos relacionados con las colisiones. En otras palabras,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49904b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C_YEAR': [1999,\n",
       "  2000,\n",
       "  2001,\n",
       "  2002,\n",
       "  2003,\n",
       "  2004,\n",
       "  2005,\n",
       "  2006,\n",
       "  2007,\n",
       "  2008,\n",
       "  2009,\n",
       "  2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2013,\n",
       "  2014],\n",
       " 'cos_C_MNTH': [0.8660254037844387,\n",
       "  0.5000000000000001,\n",
       "  6.123233995736766e-17,\n",
       "  -0.4999999999999998,\n",
       "  -0.8660254037844387,\n",
       "  -1.0,\n",
       "  -0.8660254037844388,\n",
       "  -0.5000000000000004,\n",
       "  -1.8369701987210297e-16,\n",
       "  0.5,\n",
       "  0.8660254037844384,\n",
       "  1.0,\n",
       "  <NA>],\n",
       " 'sin_C_MNTH': [0.49999999999999994,\n",
       "  0.8660254037844386,\n",
       "  1.0,\n",
       "  0.8660254037844388,\n",
       "  1.2246467991473532e-16,\n",
       "  -0.4999999999999998,\n",
       "  -0.8660254037844384,\n",
       "  -1.0,\n",
       "  -0.8660254037844386,\n",
       "  -0.5000000000000004,\n",
       "  -2.4492935982947064e-16,\n",
       "  <NA>],\n",
       " 'cos_C_WDAY': [0.6234898018587336,\n",
       "  -0.22252093395631434,\n",
       "  -0.900968867902419,\n",
       "  -0.9009688679024191,\n",
       "  -0.2225209339563146,\n",
       "  0.6234898018587334,\n",
       "  1.0,\n",
       "  <NA>],\n",
       " 'sin_C_WDAY': [0.7818314824680297,\n",
       "  0.9749279121818236,\n",
       "  0.43388373911755823,\n",
       "  -0.433883739117558,\n",
       "  -0.9749279121818235,\n",
       "  -0.7818314824680299,\n",
       "  -2.4492935982947064e-16,\n",
       "  <NA>],\n",
       " 'cos_C_HOUR': [0.6825531432186541,\n",
       "  -0.576680322114867,\n",
       "  -0.06824241336467046,\n",
       "  -0.5766803221148673,\n",
       "  -0.7757112907044198,\n",
       "  0.9629172873477994,\n",
       "  -0.9906859460363306,\n",
       "  -0.9172113015054529,\n",
       "  0.4600650377311516,\n",
       "  -0.3348796121709864,\n",
       "  -0.7757112907044197,\n",
       "  0.8544194045464886,\n",
       "  0.20345601305263328,\n",
       "  -0.9906859460363308,\n",
       "  -0.917211301505453,\n",
       "  1.0,\n",
       "  -0.06824241336467089,\n",
       "  -0.33487961217098616,\n",
       "  <NA>,\n",
       "  0.20345601305263375,\n",
       "  0.962917287347799,\n",
       "  0.46006503773115215],\n",
       " 'sin_C_HOUR': [-0.730835964278124,\n",
       "  0.8169698930104421,\n",
       "  -0.9976687691905393,\n",
       "  -0.8169698930104419,\n",
       "  -0.6310879443260529,\n",
       "  0.2697967711570243,\n",
       "  0.13616664909624707,\n",
       "  -0.39840108984624156,\n",
       "  -0.8878852184023756,\n",
       "  -0.9422609221188204,\n",
       "  0.631087944326053,\n",
       "  0.5195839500354336,\n",
       "  -0.979084087682323,\n",
       "  -0.13616664909624643,\n",
       "  0.3984010898462414,\n",
       "  -2.4492935982947064e-16,\n",
       "  0.0,\n",
       "  0.9976687691905392,\n",
       "  0.9422609221188205,\n",
       "  -0.5195839500354336,\n",
       "  <NA>,\n",
       "  0.9790840876823229,\n",
       "  -0.2697967711570252,\n",
       "  0.730835964278124,\n",
       "  0.8878852184023752],\n",
       " 'C_SEV': [2, 1],\n",
       " 'C_CONF': ['03', '01', 'QQ', '02', None, '04'],\n",
       " 'C_RCFG': [None, 'QQ', '01', '02'],\n",
       " 'C_WTHR': ['01', '02', None, 'Q'],\n",
       " 'C_RSUR': ['02', '01', None, 'Q'],\n",
       " 'C_RALN': ['02', '01', None, 'Q'],\n",
       " 'C_TRAF': ['01', '03', None, 'QQ']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores_unicos(df_pd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051dede",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e49751",
   "metadata": {},
   "source": [
    "## Separación en train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033af34",
   "metadata": {},
   "source": [
    "Eliminamos la variable objetivo C_SEV y creamos el data frame X. Por otro lado, con la variable C_SEV únicamente, creamos el objeto Y que representará nuestra variable target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b4ca618",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pd_data.drop([\"C_SEV\"], axis = 1)\n",
    "Y = df_pd_data.C_SEV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af82b8c",
   "metadata": {},
   "source": [
    "Mostramos el data frame X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b639bc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_YEAR</th>\n",
       "      <th>cos_C_MNTH</th>\n",
       "      <th>sin_C_MNTH</th>\n",
       "      <th>cos_C_WDAY</th>\n",
       "      <th>sin_C_WDAY</th>\n",
       "      <th>cos_C_HOUR</th>\n",
       "      <th>sin_C_HOUR</th>\n",
       "      <th>C_VEHS</th>\n",
       "      <th>C_CONF</th>\n",
       "      <th>C_RCFG</th>\n",
       "      <th>C_WTHR</th>\n",
       "      <th>C_RSUR</th>\n",
       "      <th>C_RALN</th>\n",
       "      <th>C_TRAF</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.682553</td>\n",
       "      <td>-0.730836</td>\n",
       "      <td>2</td>\n",
       "      <td>03</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.682553</td>\n",
       "      <td>-0.730836</td>\n",
       "      <td>2</td>\n",
       "      <td>03</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>-0.57668</td>\n",
       "      <td>0.81697</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>-0.068242</td>\n",
       "      <td>-0.997669</td>\n",
       "      <td>3</td>\n",
       "      <td>QQ</td>\n",
       "      <td>QQ</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>-0.068242</td>\n",
       "      <td>-0.997669</td>\n",
       "      <td>3</td>\n",
       "      <td>QQ</td>\n",
       "      <td>QQ</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902109</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902110</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902111</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902112</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902113</th>\n",
       "      <td>2014</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.775711</td>\n",
       "      <td>-0.631088</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3902114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         C_YEAR  cos_C_MNTH  sin_C_MNTH  cos_C_WDAY  sin_C_WDAY  cos_C_HOUR  \\\n",
       "0          1999    0.866025         0.5     0.62349    0.781831    0.682553   \n",
       "1          1999    0.866025         0.5     0.62349    0.781831    0.682553   \n",
       "2          1999    0.866025         0.5     0.62349    0.781831    -0.57668   \n",
       "3          1999    0.866025         0.5     0.62349    0.781831   -0.068242   \n",
       "4          1999    0.866025         0.5     0.62349    0.781831   -0.068242   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "3902109    2014        <NA>        <NA>        <NA>        <NA>        <NA>   \n",
       "3902110    2014        <NA>        <NA>        <NA>        <NA>        <NA>   \n",
       "3902111    2014        <NA>        <NA>        <NA>        <NA>        <NA>   \n",
       "3902112    2014        <NA>        <NA>        <NA>        <NA>        <NA>   \n",
       "3902113    2014        <NA>        <NA>        <NA>        <NA>   -0.775711   \n",
       "\n",
       "         sin_C_HOUR  C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN C_TRAF  Random  \n",
       "0         -0.730836       2     03   None     01     02     02     01      98  \n",
       "1         -0.730836       2     03   None     01     02     02     01      61  \n",
       "2           0.81697       1     01   None     02     02     02     03      22  \n",
       "3         -0.997669       3     QQ     QQ     01     02     01     01      75  \n",
       "4         -0.997669       3     QQ     QQ     01     02     01     01      16  \n",
       "...             ...     ...    ...    ...    ...    ...    ...    ...     ...  \n",
       "3902109        <NA>    <NA>   None     01   None   None   None   None      36  \n",
       "3902110        <NA>    <NA>   None     01   None   None   None   None      68  \n",
       "3902111        <NA>    <NA>   None     01   None   None   None   None      30  \n",
       "3902112        <NA>    <NA>   None     01   None   None   None   None      52  \n",
       "3902113   -0.631088       1     01     01     01     02     02     03      68  \n",
       "\n",
       "[3902114 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = LabelEncoder().fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a135979",
   "metadata": {},
   "source": [
    "LabelEconder() otorga etiquetas categóricas según el valor que puede tomar nuestra variable target. En este caso, 2=1 (1 = No fallecidos) y 1=0 (0= Al menos un fallecido)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918cc4a",
   "metadata": {},
   "source": [
    "Separamos en train y test con una semilla de 0 y un tamaño de 75% y 25% para el conjunto de train y test respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ef6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5519cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4e53c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c983f",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d1c81",
   "metadata": {},
   "source": [
    "Dado que tenemos un dataset desbalanceado (véase notebook *01_EDA*) nuestro objetivo será hacer uso de la técnica de oversampling, la cual explicaremos más adelante, para dotar de mayor información a los modelos a la hora de entrenar. Pero, para poder realizar el oversampling sobre el conjunto de datos, deberemos realizar varios cambios a las columnas, en función si son numéricas o de tipo object.\n",
    "- Si las columnas son numéricas, se deberá imputar sus valores y missing y, posteriormente hacer un escalado.\n",
    "- Si las columnas son categóricas, o de tipo object, se deberá hacer una codificación de las mismas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6ee34",
   "metadata": {},
   "source": [
    "Para realizar estas modificaciones haremos uso de los *Pipeline*. \n",
    "\n",
    "**Def.** Pipeline es un objeto que sirve para realizar una secuencia de diferentes transformaciones. \n",
    "\n",
    "Nosotros, en este caso, utilizaremos el pipeline para realizar, para cada tipo de columna, los pasos mencionados anteriormente. Es por ello que trataremos con dos pipelines, por un lado el de las columnas numéricas y, por otro, el de las columnas categóricas. \n",
    "\n",
    "Para las columnas numéricas realizaremos en primer lugar una imputación de los valores missing por la moda y después escalaremos las columnas mediante el StandardScaler (véase explicación de StandardScaler en *01_EDA*). Para las columnas categóricas, sin embargo, nos bastará únicamente con codificar la variable con el OneHotEncoding.\n",
    "\n",
    "**Def.** El one hot encoding crea una columna nueva para cada valor distinto que exista en la variable a codificar. Cada registro se marca con el valor uno en la columna a la que pertenece el valor y los demás registros tomarán el valor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e356692",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_transform = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec16a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_NA = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transform = Pipeline(steps=[('ohe', OneHotEncoder())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe3255",
   "metadata": {},
   "source": [
    "Ahora, necesitamos seleccionar las columnas numéricas y categóricas. Esto lo hacemos de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = df_pd_data.select_dtypes(include=['int', \"float\"]).drop([\"C_SEV\"], axis=1).columns\n",
    "int_data = df_pd_data.select_dtypes(include=['int']).drop([\"C_SEV\"], axis=1).columns\n",
    "cat_data = df_pd_data.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54771906",
   "metadata": {},
   "source": [
    "Para poder llevar a cabo el pipeline necesitamos del estimador *ColumnTransformer*. Esta función permite transformar, de forma separada, diferentes columnas y luego se concatenan los resultados para obtener un único dataset. Para nosotros es perfecto ya que no todas nuestras columnas del dataset necesitan ser modificadas de la misma manera como hemos podido ver anteriormente.\n",
    "\n",
    "A las columnas numéricas les aplicaremos el pipeline numérico y a las categóricas el pipeline categórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca7f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('NA', impute_NA, numeric_data),\n",
    "        ('cat', categorical_transform, cat_data),\n",
    "        (\"num\", scaled_transform, int_data)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b97e76",
   "metadata": {},
   "source": [
    "Debido a que, de momento, no nos interesa escalar el test, hemos tenido problemas a la hora de intentar hacer un nuevo pipeline para el test. La única modificación que haremos en el test será la imputación de los NAs. Esta la haremos a mano de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd284f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessor.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90721609",
   "metadata": {},
   "source": [
    "Entrenamos nuestro estimador con los datos de training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35729275",
   "metadata": {},
   "source": [
    "Ahora ya podemos transformar nuestros datos mediante el atributo .transform. Lo haremos de los datos de training únicamente, de momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = preprocessor.transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = preprocessor.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25349d43",
   "metadata": {},
   "source": [
    "Para obtener los datos en formato de data frame necesitamos pasarlos, precisamente, a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d48f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(xtrain, columns=get_feature_names(preprocessor))\n",
    "x_test = pd.DataFrame(xtest, columns=get_feature_names(preprocessor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba3dc3",
   "metadata": {},
   "source": [
    "Comprobamos que, efectivamente, ya no tenemos ningún valor nulo en el dataset de training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3937718",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unicos(x_train, k=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ba11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.drop([\"NA_C_VEHS\", \"NA_C_YEAR\", \"NA_Random\"], axis=1)\n",
    "x_test=x_test.drop([\"NA_C_VEHS\", \"NA_C_YEAR\", \"NA_Random\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e105bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas=x_train.drop(['NA_cos_C_MNTH', 'NA_sin_C_MNTH', 'NA_cos_C_WDAY', 'NA_sin_C_WDAY', 'NA_cos_C_HOUR', 'NA_sin_C_HOUR', \"num_C_YEAR\", \"num_C_VEHS\", \"num_Random\"], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d907382",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[columnas] = x_train[columnas].astype(\"int\")\n",
    "x_test[columnas]=x_test[columnas].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97800562",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67693334",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea99011",
   "metadata": {},
   "source": [
    "Dado que tenemos los datos transformados, ya estamos en condiciones de introducir nuestro conjunto de testing en un algoritmo de oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec67cf",
   "metadata": {},
   "source": [
    "## Oversampling (SMOTE algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ea67b",
   "metadata": {},
   "source": [
    "Como hemos podido comprobar en el notebook *01_EDA*, el dataset con el que estamos trabajando está realmente desbalanceado. Nuestra variable objetivo tiene muchos menos fallecidos que no fallecidos. Debido a esto, si introducimos en el modelo estos datos, no será posible obtener un buen modelo, pues no le estaremos dotando de suficiente información para que pueda predecir de manera correcta cuando haya algún fallecido. \n",
    "\n",
    "Teniendo en cuenta esto, existen dos grandes técnicas para solucionar este problema. Estas son *undersampling* y *oversampling*. Esta última consiste en generar datos \"aleatorios\" en la clase mayoritaria, para así poder dotar de información suficiente al entrenamiento del modelo. En cambio, el *undersampling* consiste en lo contrario, eliminar datos \"aleatorios\" de la clase mayoritaria de manera que ambas clases queden menos desvalanceadas. \n",
    "\n",
    "Nosotros haremos uso de *oversampling* y para ello utilizaremos uno de los algoritmos más utilizados en estas técnicas (SMOTE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8d52d",
   "metadata": {},
   "source": [
    "**Def.** SMOTE (Synthetic Minority Oversampling Technique) utiliza un algoritmo de vecino k-más cercano para crear datos sintéticos. SMOTE primero comienza eligiendo datos aleatorios de la clase minoritaria, luego se establecen los k vecinos más cercanos de los datos. Los datos sintéticos se harían entonces entre los datos aleatorios y el vecino k más cercano seleccionado al azar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a830b",
   "metadata": {},
   "source": [
    "**Ejemplo.** En el siguiente ejemplo podremos ver cómo trata de crear el algoritmo los nuevos datos sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b787d0c",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "     <td>Before SMOTE</td>\n",
    "     <td>After SMOTE</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"SMOTE_before.png\" width=\"300\" hspace=\"100\"/> \n",
    "    <td><img src=\"SMOTE_after.png\" width=\"300\"/>\n",
    "  </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e4627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Antes del OverSampling, número de '1's: {}\".format(sum(ytrain == 1)))\n",
    "print(\"Antes del OverSampling, número de '0's: {} \\n\".format(sum(ytrain == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066952a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 2, sampling_strategy=0.5)\n",
    "X_train_oversampled, y_train_oversampled = sm.fit_resample(x_train, ytrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781be00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Después del OverSampling, el tamaño de train_X: {}'.format(X_train_oversampled.shape))\n",
    "print('Después del OverSampling, el tamaño de train_y: {} \\n'.format(y_train_oversampled.shape))\n",
    " \n",
    "print(\"Después del OverSampling, número de '1's: {}\".format(sum(y_train_oversampled == 1)))\n",
    "print(\"Después del OverSampling, número de '0's: {}\".format(sum(y_train_oversampled == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6a71c",
   "metadata": {},
   "source": [
    "Una vez tenemos los conjuntos de training y testing definitivos, vamos a pasarlos a formato parquet para poder utilizarlos en otros notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc662ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_X_train = pa.Table.from_pandas(X_train_oversampled, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table_X_train, '/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big practice_data/X_train_oversampled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613718ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ytrain = pa.Table.from_pandas(pd.DataFrame(ytest), preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b156bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table_ytrain, '/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big practice_data/y_train_oversampled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ad2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_xtest = pa.Table.from_pandas(x_test, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64de4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table_xtest, '/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big practice_data/x_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00266b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ytest = pa.Table.from_pandas(pd.DataFrame(ytest), preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table_ytest, '/Users/aitor/Desktop/Máster Ciencia de Datos/Aprendizaje automático/Machine-Learning/big practice_data/ytest.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML_big_practice]",
   "language": "python",
   "name": "conda-env-ML_big_practice-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
